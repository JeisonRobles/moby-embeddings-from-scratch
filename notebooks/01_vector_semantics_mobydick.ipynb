{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Analysis Over Mobby Dick Lecture\n",
    "\n",
    "About me:\n",
    "I am Jeison Robbles Arias, a very enthucistic person focused on improving skills, education growing and difunding engineering.\n",
    "Can Fallow Me through:\n",
    "- [Medium](https://medium.com/@roblesjeison)\n",
    "- [Linkedin](https://www.linkedin.com/in/jeison-robles-arias-6ab8a9ba/)\n",
    "- [GitHub](https://github.com/JeisonRobles)\n",
    "\n",
    "<br>**Notebook focus:**</br></br>\n",
    "This note book steps over the basics about document preprocesing, embeding creation, semantic spaces and clustering for insight extraction.\n",
    "\n",
    "Along this analysis I use usual tools and strategies in a common basic pipeline to extract information about documents. Information that  can be used as a RAG file for LLM and Agentic Systems that lather I'll be using in  further publications.\n",
    "\n",
    "The document will be structured as follows:\n",
    "\n",
    "[Basic knowledge and strategy](#basics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/jeisonroblesarias/Documents/ODSC_2026/moby-embeddings-from-stratch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook-safe project root (assumes notebook is in /notebooks)\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from src.preprocess import PreprocessConfig, make_paragraph_dataset\n",
    "from src.vectorize_tfidf import TfidfConfig, build_tfidf_matrix\n",
    "from src.similarity import top_k_similar_rows\n",
    "from src.reduce_dim import pca_2d\n",
    "from src.viz import plot_embeddings_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/jeisonroblesarias/Documents/ODSC_2026/moby-embeddings-from-stratch/data/raw/mobydick.txt'),\n",
       " PosixPath('/Users/jeisonroblesarias/Documents/ODSC_2026/moby-embeddings-from-stratch/outputs'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\" / \"mobydick.txt\"\n",
    "OUTPUTS = PROJECT_ROOT / \"outputs\"\n",
    "OUTPUTS.mkdir(exist_ok=True)\n",
    "\n",
    "DATA_RAW, OUTPUTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chars: 1238242\n",
      "The Project Gutenberg eBook of Moby Dick; Or, The Whale\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBo\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_RAW, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Chars:\", len(raw_text))\n",
    "print(raw_text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction & goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphs: 1567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This text is a combination of etexts, one from...</td>\n",
       "      <td>this text is a combination of etexts one from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The pale Usher—threadbare in coat, heart, body...</td>\n",
       "      <td>the pale usher threadbare in coat heart body a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>“While you take in hand to school others, and ...</td>\n",
       "      <td>while you take in hand to school others and to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id                                           raw_text  \\\n",
       "0             0  This text is a combination of etexts, one from...   \n",
       "1             1  The pale Usher—threadbare in coat, heart, body...   \n",
       "2             2  “While you take in hand to school others, and ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  this text is a combination of etexts one from ...  \n",
       "1  the pale usher threadbare in coat heart body a...  \n",
       "2  while you take in hand to school others and to...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = PreprocessConfig(\n",
    "    min_paragraph_chars=200,  # increase if you want fewer, richer paragraphs\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "rows = make_paragraph_dataset(raw_text, cfg)\n",
    "df = pd.DataFrame(rows, columns=[\"paragraph_id\", \"raw_text\", \"clean_text\"])\n",
    "\n",
    "print(\"Paragraphs:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_len</th>\n",
       "      <th>word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1567.00000</td>\n",
       "      <td>1567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>684.92023</td>\n",
       "      <td>127.462668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>479.11573</td>\n",
       "      <td>89.246217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200.00000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>347.00000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>541.00000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>884.00000</td>\n",
       "      <td>163.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3466.00000</td>\n",
       "      <td>734.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         char_len     word_len\n",
       "count  1567.00000  1567.000000\n",
       "mean    684.92023   127.462668\n",
       "std     479.11573    89.246217\n",
       "min     200.00000    32.000000\n",
       "25%     347.00000    65.000000\n",
       "50%     541.00000   101.000000\n",
       "75%     884.00000   163.000000\n",
       "max    3466.00000   734.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"char_len\"] = df[\"clean_text\"].str.len()\n",
    "df[\"word_len\"] = df[\"clean_text\"].str.split().str.len()\n",
    "\n",
    "df[[\"char_len\", \"word_len\"]].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW:\n",
      " This text is a combination of etexts, one from the now-defunct ERIS\n",
      "project at Virginia Tech and one from Project Gutenberg’s archives. The\n",
      "proofreaders of this version are indebted to The University of Adelaide\n",
      "Library for preserving the Virginia Tech version. The resulting etext\n",
      "was compared with a public domain hard copy version of the text.\n",
      "\n",
      "CLEAN:\n",
      " this text is a combination of etexts one from the now defunct eris project at virginia tech and one from project gutenberg s archives the proofreaders of this version are indebted to the university of adelaide library for preserving the virginia tech version the resulting etext was compared with a public domain hard copy version of the text\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"RAW:\\n\", df.loc[i, \"raw_text\"][:700])\n",
    "print(\"\\nCLEAN:\\n\", df.loc[i, \"clean_text\"][:700])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (1567, 6838)\n"
     ]
    }
   ],
   "source": [
    "tfidf_cfg = TfidfConfig(\n",
    "    min_df=3,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 2),     # unigrams + bigrams makes it feel “semantic”\n",
    "    stop_words=\"english\",\n",
    "    sublinear_tf=True,\n",
    "    norm=\"l2\"               # important: L2 normalization makes cosine meaningful\n",
    ")\n",
    "\n",
    "X, vectorizer = build_tfidf_matrix(df[\"clean_text\"].tolist(), tfidf_cfg)\n",
    "\n",
    "print(\"TF-IDF shape:\", X.shape)  # (num_paragraphs, num_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY PARAGRAPH:\n",
      "\n",
      "“Which to secure, no skill of leach’s art Mote him availle, but to\n",
      " returne againe To his wound’s worker, that with lowly dart, Dinting\n",
      " his breast, had bred his restless paine, Like as the wounded whale to\n",
      " shore flies thro’ the maine.” —_The Fairie Queen_. ...\n",
      "\n",
      "TOP NEIGHBORS:\n",
      "\n",
      "\n",
      "Score: 0.132 | paragraph_id=1091\n",
      "In his treatise on “Queen-Gold,” or Queen-pinmoney, an old King’s Bench\n",
      "author, one William Prynne, thus discourseth: “Ye tail is ye Queen’s,\n",
      "that ye Queen’s wardrobe may be supplied with ye whalebone.” Now this\n",
      "was written at a time when the black limber bone of the Greenland or\n",
      "Right whale was largely used in ladies’ bodices. But this same bone is\n",
      "not in the tail; it is in the head, which is a sad mistake for a\n",
      "sagacious lawyer like Prynne. But ...\n",
      "\n",
      "Score: 0.116 | paragraph_id=1286\n",
      "“Thou art but too good a fellow, Starbuck,” he said lowly to the mate;\n",
      "then raising his voice to the crew: “Furl the t’gallant-sails, and\n",
      "close-reef the top-sails, fore and aft; back the main-yard; up Burton,\n",
      "and break out in the main-hold.” ...\n",
      "\n",
      "Score: 0.112 | paragraph_id=127\n",
      "No town-bred dandy will compare with a country-bred one—I mean a\n",
      "downright bumpkin dandy—a fellow that, in the dog-days, will mow his\n",
      "two acres in buckskin gloves for fear of tanning his hands. Now when a\n",
      "country dandy like this takes it into his head to make a distinguished\n",
      "reputation, and joins the great whale-fishery, you should see the\n",
      "comical things he does upon reaching the seaport. In bespeaking his\n",
      "sea-outfit, he orders bell-buttons to hi ...\n",
      "\n",
      "Score: 0.109 | paragraph_id=1192\n",
      "“Yes, I may as well,” said the surgeon, coolly. “I was about observing,\n",
      "sir, before Captain Boomer’s facetious interruption, that spite of my\n",
      "best and severest endeavors, the wound kept getting worse and worse;\n",
      "the truth was, sir, it was as ugly gaping wound as surgeon ever saw;\n",
      "more than two feet and several inches long. I measured it with the lead\n",
      "line. In short, it grew black; I knew what was threatened, and off it\n",
      "came. But I had no hand in s ...\n",
      "\n",
      "Score: 0.099 | paragraph_id=1342\n",
      "“Oh, thou dark Hindoo half of nature, who of drowned bones hast builded\n",
      "thy separate throne somewhere in the heart of these unverdured seas;\n",
      "thou art an infidel, thou queen, and too truly speakest to me in the\n",
      "wide-slaughtering Typhoon, and the hushed burial of its after calm. Nor\n",
      "has this thy whale sunwards turned his dying head, and then gone round\n",
      "again, without a lesson to me. ...\n"
     ]
    }
   ],
   "source": [
    "query_idx = 10  # change this\n",
    "neighbors = top_k_similar_rows(X, query_idx, k=5)\n",
    "\n",
    "print(\"QUERY PARAGRAPH:\\n\")\n",
    "print(df.loc[query_idx, \"raw_text\"][:600], \"...\\n\")\n",
    "\n",
    "print(\"TOP NEIGHBORS:\\n\")\n",
    "for idx, score in neighbors:\n",
    "    print(f\"\\nScore: {score:.3f} | paragraph_id={df.loc[idx, 'paragraph_id']}\")\n",
    "    print(df.loc[idx, \"raw_text\"][:450], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jeisonroblesarias/Documents/ODSC_2026/moby-embeddings-from-stratch/outputs/neighbors.csv\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for idx, score in neighbors:\n",
    "    records.append({\n",
    "        \"query_idx\": query_idx,\n",
    "        \"neighbor_idx\": idx,\n",
    "        \"cosine_score\": score,\n",
    "        \"neighbor_snippet\": df.loc[idx, \"raw_text\"][:250].replace(\"\\n\", \" \")\n",
    "    })\n",
    "\n",
    "pd.DataFrame(records).to_csv(OUTPUTS / \"neighbors.csv\", index=False)\n",
    "print(\"Saved:\", OUTPUTS / \"neighbors.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot: /Users/jeisonroblesarias/Documents/ODSC_2026/moby-embeddings-from-stratch/outputs/embedding_plot.html\n"
     ]
    }
   ],
   "source": [
    "coords = pca_2d(X)\n",
    "\n",
    "df_plot = pd.DataFrame({\n",
    "    \"x\": coords[:, 0],\n",
    "    \"y\": coords[:, 1],\n",
    "    \"paragraph_id\": df[\"paragraph_id\"],\n",
    "    \"snippet\": df[\"raw_text\"].str.replace(\"\\n\", \" \").str[:200]\n",
    "})\n",
    "\n",
    "out_html = OUTPUTS / \"embedding_plot.html\"\n",
    "plot_embeddings_2d(df_plot, str(out_html))\n",
    "\n",
    "print(\"Saved plot:\", out_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Strip Gutenberg boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Paragraph segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Text normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. TF-IDF embedings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Cosine similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 2D semantic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Insights & takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
